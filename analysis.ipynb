{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Forum Question Analyzer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fba23e515491b9"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Load the dataset from the extracted .xml files.\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Forum Question Analyzer\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.databricks:spark-xml_2.12:0.17.0\") \\\n",
    "    .getOrCreate()\n",
    "posts = spark.read \\\n",
    "    .format(\"com.databricks.spark.xml\") \\\n",
    "    .option(\"rootTag\", \"posts\") \\\n",
    "    .option(\"rowTag\", \"row\") \\\n",
    "    .load(\"tex.stackexchange.com/Posts.xml\") \\\n",
    "    .alias('posts')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T22:26:45.394616100Z",
     "start_time": "2024-01-16T22:26:15.036696600Z"
    }
   },
   "id": "e1ebdb68d9ddea42"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+--------------------+--------------------+-------------+-------------------+---------------+--------------------+--------------+---+--------------------+--------------------+----------------------+-----------------+-----------------+------------+---------+-----------+------+--------------------+--------------------+----------+\n",
      "|_AcceptedAnswerId|_AnswerCount|               _Body|         _ClosedDate|_CommentCount|_CommunityOwnedDate|_ContentLicense|       _CreationDate|_FavoriteCount|_Id|   _LastActivityDate|       _LastEditDate|_LastEditorDisplayName|_LastEditorUserId|_OwnerDisplayName|_OwnerUserId|_ParentId|_PostTypeId|_Score|               _Tags|              _Title|_ViewCount|\n",
      "+-----------------+------------+--------------------+--------------------+-------------+-------------------+---------------+--------------------+--------------+---+--------------------+--------------------+----------------------+-----------------+-----------------+------------+---------+-----------+------+--------------------+--------------------+----------+\n",
      "|               17|           2|<p>I'm using LyX ...|                NULL|            0|               NULL|   CC BY-SA 2.5|2010-07-26 21:14:...|          NULL|  1|2012-03-07 13:35:...|2011-12-26 10:43:...|                  NULL|              510|             NULL|           5|     NULL|          1|     8|<macros><lyx><pre...|Automatically def...|      3089|\n",
      "|                4|           3|<blockquote>\\n  <...|2012-05-09 12:37:...|            1|               NULL|   CC BY-SA 2.5|2010-07-26 21:14:...|          NULL|  2|2012-05-09 10:52:...|2017-04-13 14:35:...|                  NULL|               -1|             NULL|           9|     NULL|          1|    11|<table-of-content...|Table of contents...|       783|\n",
      "|             1654|          21|<p>I have heard r...|                NULL|            7|               NULL|   CC BY-SA 2.5|2010-07-26 21:18:...|          NULL|  3|2023-10-03 00:52:...|2010-09-03 12:00:...|                  NULL|               83|             NULL|          14|     NULL|          1|   240|<compiling><tools...|Compiling documen...|    153764|\n",
      "|             NULL|        NULL|<p>Try <code>\\inp...|                NULL|            2|               NULL|   CC BY-SA 3.0|2010-07-26 21:19:...|          NULL|  4|2012-05-09 10:52:...|2012-05-09 10:52:...|                  NULL|             6621|             NULL|          27|        2|          2|     7|                NULL|                NULL|      NULL|\n",
      "|             NULL|        NULL|<p>The Google-rel...|                NULL|            3|               NULL|   CC BY-SA 4.0|2010-07-26 21:22:...|          NULL|  6|2018-08-03 17:44:...|2018-08-03 17:44:...|                  NULL|            73833|             NULL|          30|        3|          2|    67|                NULL|                NULL|      NULL|\n",
      "+-----------------+------------+--------------------+--------------------+-------------+-------------------+---------------+--------------------+--------------+---+--------------------+--------------------+----------------------+-----------------+-----------------+------------+---------+-----------+------+--------------------+--------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "posts.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T22:26:47.277524100Z",
     "start_time": "2024-01-16T22:26:45.395744100Z"
    }
   },
   "id": "1ead3e1168b893a5",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  584821\n",
      "Number of questions:  255804\n",
      "Number of answers:  326115\n",
      "Number of accepted answers:  153808\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics\n",
    "\n",
    "print(\"Number of rows: \", posts.count())\n",
    "print(\"Number of questions: \", posts.filter(posts._PostTypeId == 1).count())\n",
    "print(\"Number of answers: \", posts.filter(posts._PostTypeId == 2).count())\n",
    "print(\"Number of accepted answers: \", posts.filter(posts._AcceptedAnswerId.isNotNull()).count())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T22:27:48.287511900Z",
     "start_time": "2024-01-16T22:26:47.281348600Z"
    }
   },
   "id": "101a02f7eea4fbb6",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Extraction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c954147ca4a63e2d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "features = ['_Score', '_ViewCount', '_AnswerCount', '_CommentCount']\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T22:27:48.664633Z",
     "start_time": "2024-01-16T22:27:48.274874500Z"
    }
   },
   "id": "3c4b86aa3eb93155"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d67bbf49c2a008ea"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "questions = posts.filter(posts._PostTypeId == 1)\n",
    "questions = questions.withColumn(\"accepted\", when(col(\"_AcceptedAnswerId\").isNull(), 0).otherwise(1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T22:27:48.704630200Z",
     "start_time": "2024-01-16T22:27:48.667867300Z"
    }
   },
   "id": "aacfb624b53860aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "382e3519083a3422"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"accepted\", featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "train, test = questions.randomSplit([0.7, 0.3], seed=12345)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T22:27:48.758562300Z",
     "start_time": "2024-01-16T22:27:48.703538Z"
    }
   },
   "id": "d5014e0a1f9a13f5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = pipeline.fit(train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T22:28:45.013516700Z",
     "start_time": "2024-01-16T22:27:48.759630900Z"
    }
   },
   "id": "f9a3c29342f41f28"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "predictions = model.transform(test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T22:28:45.091607400Z",
     "start_time": "2024-01-16T22:28:45.016257100Z"
    }
   },
   "id": "74504727a2134dc0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82d6e5dc7e95bb1e"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.742379177327809\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"accepted\", metricName=\"accuracy\")\n",
    "print(\"Test Accuracy: \" + str(evaluator.evaluate(predictions)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T22:29:10.655595400Z",
     "start_time": "2024-01-16T22:28:45.095277700Z"
    }
   },
   "id": "d172d490df736a99"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "373ea5864e18fe40"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
