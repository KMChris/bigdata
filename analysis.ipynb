{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21e01cfc3d052772",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Predictive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1ebdb68d9ddea42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T19:36:34.757732700Z",
     "start_time": "2024-01-23T19:36:34.750485600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.sql.functions import when, col, array_max, udf, expr, size, datediff\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, ArrayType, FloatType\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f76b9ee081a89f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T18:10:24.912647600Z",
     "start_time": "2024-01-23T18:09:47.840453500Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Forum Question Analyzer\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.databricks:spark-xml_2.12:0.17.0\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "posts = spark.read \\\n",
    "    .format(\"com.databricks.spark.xml\") \\\n",
    "    .option(\"rootTag\", \"posts\") \\\n",
    "    .option(\"rowTag\", \"row\") \\\n",
    "    .load(\"tex.stackexchange.com/Posts.xml\") \\\n",
    "    .alias('posts')\n",
    "users = spark.read \\\n",
    "    .format(\"com.databricks.spark.xml\") \\\n",
    "    .option(\"rootTag\", \"users\") \\\n",
    "    .option(\"rowTag\", \"row\") \\\n",
    "    .load(\"tex.stackexchange.com/Users.xml\") \\\n",
    "    .alias('users')\n",
    "tags = spark.read \\\n",
    "    .format(\"com.databricks.spark.xml\") \\\n",
    "    .option(\"rootTag\", \"tags\") \\\n",
    "    .option(\"rowTag\", \"row\") \\\n",
    "    .load(\"tex.stackexchange.com/Tags.xml\") \\\n",
    "    .alias('tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c954147ca4a63e2d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcab8de6b06d41c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T18:10:26.638772500Z",
     "start_time": "2024-01-23T18:10:24.913685200Z"
    }
   },
   "outputs": [],
   "source": [
    "#UDF - Fast way to change tag names to tag counts from Tags table\n",
    "\n",
    "tag_counts = tags.select(\"_TagName\", \"_Count\").rdd.collectAsMap()\n",
    "\n",
    "def replace_tags_with_counts(tags):\n",
    "    return [tag_counts.get(tag, 0) for tag in tags]\n",
    "\n",
    "replace_tags_with_counts_udf = udf(replace_tags_with_counts, ArrayType(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efd7bbf74f912b60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T18:10:26.930372300Z",
     "start_time": "2024-01-23T18:10:26.642979Z"
    }
   },
   "outputs": [],
   "source": [
    "posts = posts.filter(posts._PostTypeId==1)\n",
    "questions = posts.withColumn(\"_Tags\", expr(\"split(substring(_Tags, 2, length(_Tags) - 2), '><')\"))\\\n",
    "            .withColumn(\"_Body\", size(expr(\"split(_Body, ' ')\")))\\\n",
    "            .withColumn(\"_Title\", size(expr(\"split(_Title, ' ')\")))\n",
    "\n",
    "questions = questions.join(users, questions._OwnerUserId == users._Id).select(\n",
    "    questions._Id.alias(\"QuestionId\"),\n",
    "    questions._Body.alias(\"BodyLength\"),\n",
    "    questions._Title.alias(\"TitleLength\"),\n",
    "    array_max(replace_tags_with_counts_udf(questions._Tags)).alias(\"TagsCountMax\"),\n",
    "    size(questions._Tags).alias(\"NumberOfTags\"),\n",
    "    users._Id.alias(\"OwnerId\"),\n",
    "    users._DownVotes.alias(\"OwnerDownVotes\"),\n",
    "    users._UpVotes.alias(\"OwnerUpVotes\"),\n",
    "    users._Reputation.alias(\"OwnerReputation\"),\n",
    "    users._Views.alias(\"OwnerViews\"),\n",
    "    datediff(questions._CreationDate, users._CreationDate).alias(\"OwnerExperience\"),\n",
    "    when(col(\"_AcceptedAnswerId\").isNull(), 0).otherwise(1).alias(\"Accepted\")\n",
    ")\n",
    "\n",
    "questions = questions.filter(questions.OwnerExperience >= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67bbf49c2a008ea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4b86aa3eb93155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T19:36:38.204290Z",
     "start_time": "2024-01-23T19:36:38.189770800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['OwnerUpVotes', 'OwnerReputation', 'OwnerViews', 'OwnerExperience', 'TagsCountMax', 'OwnerDownVotes']\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"rawfeatures\")\n",
    "scaler = StandardScaler(inputCol=\"rawfeatures\", outputCol=\"scaledFeatures\", withMean=True, withStd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf8144da797e31d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T19:36:39.745638700Z",
     "start_time": "2024-01-23T19:36:39.729033400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = questions.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382e3519083a3422",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5014e0a1f9a13f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T19:39:27.681290200Z",
     "start_time": "2024-01-23T19:36:40.600449200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "lr = LogisticRegression(labelCol=\"Accepted\", featuresCol=\"scaledFeatures\", maxIter=100)\n",
    "lr_pipeline = Pipeline(stages=[assembler, scaler, lr])\n",
    "lr_model = lr_pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346ffc6627dbd121",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T19:43:02.864138300Z",
     "start_time": "2024-01-23T19:39:27.683994200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forest model\n",
    "rf = RandomForestClassifier(labelCol=\"Accepted\", featuresCol=\"scaledFeatures\", numTrees=100)\n",
    "rf_pipeline = Pipeline(stages=[assembler, scaler, rf])\n",
    "rf_model = rf_pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6300714e9c0f9365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T19:45:06.401487600Z",
     "start_time": "2024-01-23T19:43:02.866133200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting model\n",
    "gbt = GBTClassifier(labelCol=\"Accepted\", featuresCol=\"scaledFeatures\", maxIter=100)\n",
    "gbt_pipeline = Pipeline(stages=[assembler, scaler, gbt])\n",
    "gbt_model = gbt_pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9a3c29342f41f28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T19:47:58.408827400Z",
     "start_time": "2024-01-23T19:45:06.404734300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Neural Network model\n",
    "layers = [len(features), 10, 8, 2]  # Adjust layer sizes as needed\n",
    "nn = MultilayerPerceptronClassifier(labelCol=\"Accepted\", featuresCol=\"scaledFeatures\", layers=layers, blockSize=128)\n",
    "nn_pipeline = Pipeline(stages=[assembler, scaler, nn])\n",
    "nn_model = nn_pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b713ee9d56b629e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74504727a2134dc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T19:47:58.843994900Z",
     "start_time": "2024-01-23T19:47:58.408827400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_predictions = lr_model.transform(test)\n",
    "rf_predictions = rf_model.transform(test)\n",
    "gbt_predictions = gbt_model.transform(test)\n",
    "nn_predictions = nn_model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d6e5dc7e95bb1e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(predictions):\n",
    "    predictionAndLabels = predictions.select(\"prediction\", \"Accepted\")\\\n",
    "        .rdd.map(lambda row: (float(row[\"prediction\"]), float(row[\"Accepted\"])))\n",
    "    \n",
    "    confmat = MulticlassMetrics(predictionAndLabels).confusionMatrix().toArray()\n",
    "\n",
    "    TP = confmat[0, 0]\n",
    "    FP = confmat[0, 1]\n",
    "    FN = confmat[1, 0]\n",
    "    TN = confmat[1, 1]\n",
    "\n",
    "    #Bookmaker informedness\n",
    "    if (TN + FP == 0) or (TP + FN == 0):\n",
    "        BI = \"BI measure cannot be calculated\"\n",
    "    else:\n",
    "        TNR = TN / (TN + FP)\n",
    "        TPR = TP / (TP + FN)\n",
    "        BI = TPR + TNR - 1\n",
    "\n",
    "    #Matthews correlation coefficient\n",
    "    #Case when entire row/column is 0\n",
    "    if (TP + FP) * (TP + FN) * (TN + FP) * (TN + FN) == 0:\n",
    "        MCC = 0\n",
    "    else:\n",
    "        MCC = (TP * TN - FP * FN) / ((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))**0.5\n",
    "\n",
    "    #Accuracy\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "    return [accuracy, BI, MCC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Accuracy =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jurek\\anaconda3\\lib\\site-packages\\pyspark\\sql\\context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression : accuracy = 59.946%, BI measure cannot be calculated, MCC = 0.0000.\n",
      "random forest       : accuracy = 70.370%, BI = 0.4245699672249277, MCC = 0.3638.\n",
      "gradient boosting   : accuracy = 71.023%, BI = 0.4286597313739091, MCC = 0.3783.\n",
      "neural network      : accuracy = 66.468%, BI = 0.3064367015966454, MCC = 0.2709.\n"
     ]
    }
   ],
   "source": [
    "print('===== Accuracy =====')\n",
    "for name, pred in [\n",
    "    (\"logistic regression\", lr_predictions),\n",
    "    (\"random forest      \", rf_predictions),\n",
    "    (\"gradient boosting  \", gbt_predictions),\n",
    "    (\"neural network     \", nn_predictions)]:\n",
    "    x = metrics(pred)\n",
    "    if isinstance(x[1], float):\n",
    "        print(f'{name} : accuracy = {x[0]:.3%}, BI = {x[1]}, MCC = {x[2]:.4f}.')\n",
    "    else:\n",
    "        print(f'{name} : accuracy = {x[0]:.3%}, {x[1]}, MCC = {x[2]:.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting probability of getting an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training best model using entire data\n",
    "best_model = gbt_pipeline.fit(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(values):\n",
    "    colnames = ['BodyLength', 'TitleLength', 'TagsCountMax',\n",
    "                'NumberOfTags', 'OwnerDownVotes', 'OwnerUpVotes',\n",
    "                'OwnerReputation', 'OwnerViews', 'OwnerExperience']\n",
    "    example = spark.createDataFrame([values], colnames)\n",
    "    p = best_model.transform(example)\n",
    "    return p.collect()[0].__getitem__(\"probability\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5338136132319231"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example using most recent posts, not yet in posts dataframe (post 708098)\n",
    "prob([50, 9, 9630, 3, 0, 7, 99, 303, 273])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
